{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9556e0f8-b269-434d-bae0-4a98ecaf4f3b",
   "metadata": {},
   "source": [
    "# Justification and Discussion of negative potential (Table 1 and Table 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92169b74-a993-4f27-abd4-1a209ea1e507",
   "metadata": {},
   "source": [
    "## Get filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd4c212-b479-4474-9cb9-23227595365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_fn = '../data/annotations.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a65b7c-a628-4287-8243-a776e6fbc74a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and process annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17567341-4ab6-472c-bf22-e1247069572a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# get annotations\n",
    "annotations = pd.read_csv(annotations_fn, sep='\\t').dropna(how='all', axis='columns')  # drop empty colums\n",
    "annotations = annotations.rename({'Annotators 1 and 2': 'Annotator'}, axis=1) # rename columns\n",
    "annotations = annotations[annotations.Title.notna()].reset_index(drop=True)  # drop empty rows\n",
    "annotations = annotations[annotations.Complete.notna()].reset_index(drop=True)  # drop not done rows\n",
    "\n",
    "# get all annotations\n",
    "papers = list(annotations.Title.unique())\n",
    "annotations['Negative potential?'] = annotations['Negative potential?'].fillna(0).apply(int)\n",
    "annotations['Justification score'] = annotations['Justification score'].apply(lambda i: max(int(i),1) - 1)  # we deleted one category\n",
    "\n",
    "# get annotations that were doubly annotated (by a pair of annotators)\n",
    "for title in annotations.Title.unique():\n",
    "    n_raters = len(annotations[annotations.Title == title])\n",
    "    annotations.loc[annotations.Title == title, '# Annotations'] = n_raters\n",
    "pairs_annotations = annotations.copy()[annotations['# Annotations'] == 2.0].drop(['# Annotations'], axis=1).reset_index(drop=True)\n",
    "pairs_papers = list(pairs_annotations.Title.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463bd70-3bc5-4e5a-91a7-434eaef47660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89ec33f-7cf1-43e5-bf44-8d57c790801e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justification score\n",
      " Category 0: 68.0%\n",
      "Category 1: 17.0%\n",
      "Category 2: 11.0%\n",
      "Category 3: 4.0%\n",
      "\n",
      "Negative potential?\n",
      " Category 0: 98.0%\n",
      "Category 1: 1.0%\n",
      "Category 2: 1.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for analysis in ['Justification score', 'Negative potential?']:\n",
    "    paper_scores = [annotations[annotations.Title == paper][analysis].max() for paper in papers]\n",
    "    category_percents = (sorted({score: count * 100. / len(papers) for score, count in Counter(paper_scores).items()}.items()))\n",
    "    print(analysis+'\\n', '\\n'.join([f'Category {cat}: {percent}%' for cat, percent in category_percents]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2cefc-5a8e-4f31-9b2f-0a0fddfde369",
   "metadata": {},
   "source": [
    "## IRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e926299-912b-4fd5-a709-074eb65f9327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLEISS' WEIGHTED KAPPA\n",
      "'Justification score' Fleiss' weighted kappa: 0.6\n",
      "'Negative potential?' Fleiss' weighted kappa: 0.79\n"
     ]
    }
   ],
   "source": [
    "# IRR: Fleiss' weighted kappa\n",
    "print(\"FLEISS' WEIGHTED KAPPA\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "for category in ['Justification score', 'Negative potential?']:\n",
    "    a1, a2 = zip(*[list(pairs_annotations.loc[pairs_annotations.Title == paper, category]) for paper in pairs_papers])\n",
    "    kappa = cohen_kappa_score(a1, a2, weights='linear')\n",
    "    print(f\"'{category}' Fleiss' weighted kappa: {kappa:.2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
