Year	Venue   	Note   	Title	URL	Annotators 1 and 2	Complete	# Annotations	Reviewed for agreement	Comments	Justification score	Kind of task	Negative potential?	Value Totals																																																																									
													General																							Performance												Advances understanding in the field								Practical application											User rights									Principles							Additional			
										Is the societal need/justification for this paper well-defended?                                                                                        0=Doesn't rigorously justify how it achieves internal goal                                                                              1=Justifies how it achieves internal goal but no mention of any societal need                                                                                                                                                                              2=States but does not justify how it connect to a societal need                                                                                         3=States and somewhat justifies how it connects to a societal need                                                                                                                                                                          4=States and rigorously justifies how it connects to a a societal need	"At a high level, what task does this paper say it is engaged in? (Classification, Prediction, Generation, Understanding, Defenses, Transparency, Something else?)"	To what extent does the paper engage with negative potential?                                                                                       0=Doesn't mention negative potential                                                                            1=Only mentions negative potential                                                                                        2=Discusses negative potential                                                                                                                                                                         3=Deepens our understanding of negative potential	Novelty	Simplicity	Generalization	Flexibility/Extensibility	Robustness	Realistic output	Formal description/analysis	Theoretical guarantees	Approximation	Quantitative evidence (e.g. experiments)	Qualitative evidence (e.g. examples)	Scientific methodology	Controllability (of model owner)	Human-like mechanism	Low cost	Large scale	Promising	Generality	Principled	Exactness	Preciseness	Concreteness	Automatic	Performance	Accuracy	Avoiding train/test discrepancy	State-of-the-art	Efficiency	Reduced training time	Memory efficiency	Data efficiency	Label efficiency (reduced need for labeled data)	Energy efficiency	Effectiveness	Successful	Building on classic work	Building on recent work	Unifying ideas or integrating components	Identifying limitations	Critique	Understanding (for researchers)	Improvement	Progress	Used in practice/Popular	Reproducibility	Easy to implement	Requires few resources	Parallelizability / distributed	Facilitating use (e.g. sharing code)	Scales up	Applies to real world	Learning from humans	Practical	Useful	Interpretable (to users)	Transparent (to users)	Privacy	Fairness	Not socially biased	User influence	Collective influence	Deferral to humans	Critiqability	Beneficence	Non-maleficence	Justice	Respect for Persons	Autonomy (power to decide)	Explicability	Respect for Law and public interest	Security	Easy to work with	Realistic world model	Fast
																																																																																						
2019	NeurIPS		XLNet: Generalized Autoregressive Pretraining for Language Understanding	http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding	Ravit	done	2			1	NLP	0	1	0	4	3	0	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	5	0	0	2	0	0	0	0	0	0	1	2	0	16	3	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		XLNet: Generalized Autoregressive Pretraining for Language Understanding	http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding	Abeba	done				1	"NLP, generalization"	0	3	0	5	2	0	0	1	0	1	1	0	2	0	0	0	1	0	0	0	1	0	0	0	7	0	2	2	0	0	0	0	1	0	2	2	5	7	3	0	0	1	5	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	1	0	0
																																																																																						
2019	NeurIPS		Cross-lingual Language Model Pretraining	http://papers.nips.cc/paper/8928-cross-lingual-language-model-pretraining	Ria	done	2		"Re unusually high justificatory chain score: It justifies how it achieves its internal goal of improved XLU and it shows it improves the application of this work in non-English contexts as well as low-resource languages, but it does not get concrete about the societal need for multilingual models. In fact, large multilingual models are frequently used e.g. by the military for intel. Still, I think it justifies achieving its stated societal need, even if I believe that societal need is not sufficiently discussed or given nuance."	4	Translation	0	4	0	4	1	0	0	0	0	0	8	0	0	0	0	0	0	0	0	0	0	1	0	0	4	3	0	9	1	0	0	2	0	0	3	0	0	1	0	0	0	0	8	0	0	0	0	2	0	3	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		Cross-lingual Language Model Pretraining	http://papers.nips.cc/paper/8928-cross-lingual-language-model-pretraining	Ravit	done				4	Translation/Language understanding	0	3	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	3	0	10	1	0	0	0	0	0	3	0	1	1	0	0	0	0	7	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		"Adversarial Examples Are Not Bugs, They Are Features"	http://papers.nips.cc/paper/8307-adversarial-examples-are-not-bugs-they-are-features.pdf	Michelle	done	2		NEED TO REANNOTATE	1	understanding	0	0	0	0	0	17	0	1	0	0	2	0	0	0	0	0	0	0	0	0	0	1	2	0	0	3	1	1	0	0	0	0	0	0	0	0	0	2	0	1	1	12	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		"Adversarial Examples Are Not Bugs, They Are Features"	http://papers.nips.cc/paper/8307-adversarial-examples-are-not-bugs-they-are-features.pdf	Dallas	done		done		1	understanding	0	1	0	4	0	20	0	7	3	0	2	0	1	0	0	0	0	0	0	0	0	1	2	0	0	6	1	1	0	0	0	0	0	0	0	0	0	4	0	0	0	7	0	0	0	0	0	0	0	0	0	1	1	0	0	7	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent	http://papers.nips.cc/paper/9063-wide-neural-networks-of-any-depth-evolve-as-linear-models-under-gradient-descent.pdf	Ria	done	2			0	Understanding	0	1	4	9	0	1	0	21	0	0	6	0	1	0	0	0	1	0	0	0	4	1	0	0	4	2	0	0	0	0	0	0	0	0	0	0	1	4	12	1	0	20	0	0	0	0	0	0	0	2	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0
2019	NeurIPS		Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent	http://papers.nips.cc/paper/9063-wide-neural-networks-of-any-depth-evolve-as-linear-models-under-gradient-descent.pdf	Willie	done				1	Understanding	0	1	5	6	2	1	0	14	6	3	6	0	0	0	0	0	1	0	0	0	0	0	0	0	3	2	0	0	0	0	0	0	0	0	0	0	0	8	1	0	0	5	0	0	0	0	0	0	0	2	1	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		MixMatch: A Holistic Approach to Semi-Supervised Learning	http://papers.nips.cc/paper/8749-mixmatch-a-holistic-approach-to-semi-supervised-learning	Michelle	done	2			2	"describing (a new algorithm), prediction"	0	2	0	1	0	0	0	0	0	0	3	0	0	0	0	2	2	0	0	0	0	0	0	0	3	4	1	3	0	0	0	1	7	0	2	2	0	5	4	0	0	1	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		MixMatch: A Holistic Approach to Semi-Supervised Learning	http://papers.nips.cc/paper/8749-mixmatch-a-holistic-approach-to-semi-supervised-learning	Abeba	done				1	describing (a new algorithm)	0	3	1	3	2	0	0	0	0	0	3	2	0	0	0	2	2	0	0	0	0	0	0	0	2	2	1	3	0	0	0	4	10	0	2	2	0	2	4	0	0	0	1	0	0	0	0	0	0	1	0	0	0	0	1	0	0	4	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		"PyTorch: An Imperative Style, High-Performance Deep Learning Library"	http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library	Dallas	done	1			1	describing (a new system)	0	0	0	0	3	0	0	0	0	0	0	1	0	1	0	0	0	0	0	1	0	0	0	0	8	0	0	0	3	2	0	0	0	0	0	0	0	1	0	0	0	0	0	0	3	0	2	0	1	1	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		"PyTorch: An Imperative Style, High-Performance Deep Learning Library"	http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library	Ria																																																																																	
																																																																																						
2019	NeurIPS		On Exact Computation with an Infinitely Wide Neural Net	http://papers.nips.cc/paper/9025-on-exact-computation-with-an-infinitely-wide-neural-net	Dallas	done	2		unusually bad writing	1	understanding	0	3	0	5	0	0	0	2	5	2	5	0	0	0	0	0	0	0	0	0	3	0	0	0	11	1	0	0	2	0	0	0	0	0	0	0	3	2	4	0	0	6	0	0	0	0	0	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		On Exact Computation with an Infinitely Wide Neural Net	http://papers.nips.cc/paper/9025-on-exact-computation-with-an-infinitely-wide-neural-net	Michelle	done				1	"understanding, classification"	0	4	1	3	0	0	0	3	4	2	6	0	0	0	0	0	0	0	0	0	3	0	0	0	7	2	1	1	3	0	0	0	0	0	0	0	2	3	4	0	0	5	0	0	0	0	0	0	1	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		Unified Language Model Pre-training for Natural Language Understanding and Generation	http://papers.nips.cc/paper/9464-unified-language-model-pre-training-for-natural-language-understanding-and-generation	Willie	done	2			1	"Classification, prediction, generation"	0	1	0	0	9	0	0	0	0	0	5	1	0	0	0	0	0	0	0	0	0	0	0	0	3	0	0	4	1	1	0	2	5	1	1	0	0	1	0	0	0	0	0	0	0	1	0	0	0	1	0	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0				
2019	NeurIPS		Unified Language Model Pre-training for Natural Language Understanding and Generation	http://papers.nips.cc/paper/9464-unified-language-model-pre-training-for-natural-language-understanding-and-generation	Ravit	done				1	"Prediction, generalization"	0	1	0	0	8	0	0	0	0	0	2	0	0	0	0	0	1	0	1	0	0	0	0	0	3	0	0	6	1	0	0	0	0	0	1	0	0	1	0	0	0	0	1	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		Adversarial Training for Free!	http://papers.nips.cc/paper/8597-adversarial-training-for-free	Willie	done	1			3	defense	0	1	1	5	2	19	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	1	0	0	14	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	4	2	0	11	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0				
2019	NeurIPS		Adversarial Training for Free!	http://papers.nips.cc/paper/8597-adversarial-training-for-free	Ria																																																																																	
																																																																																						
2019	NeurIPS		ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks	http://papers.nips.cc/paper/8297-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.pdf	Willie	done (old)	2			1	classification	0	2	0	9	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	3	0	0	0	0	5	0	0	0	1	0	2	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	13			
2019	NeurIPS		ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks	http://papers.nips.cc/paper/8297-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.pdf	Dallas	done		"tried to check, but I couldn't find your final annoations for this one (numbers in the sheet I found don't match what is here)"	couldn't find Willie's annotations for this	1	classification	0	2	0	5	4	0	0	0	0	0	6	0	0	0	0	0	3	1	0	0	0	0	0	2	1	0	0	5	0	0	0	0	0	0	0	0	2	1	1	1	3	1	0	0	1	0	1	0	0	1	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0
																																																																																						
2019	NeurIPS		SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems	http://papers.nips.cc/paper/8589-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems	Michelle	done	2		I may reannotate because I did this early on	1	Evaluation (new benchmark)	0	5	1	4	1	1	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	6	0	0	1	0	0	0	0	2	0	1	0	0	3	0	2	0	0	1	4	0	0	0	0	0	1	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS		SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems	http://papers.nips.cc/paper/8589-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems	Abeba	done				1	understanding	1	6	2	6	1	0	0	0	0	0	0	1	0	0	3	0	0	0	6	0	0	0	0	0	6	0	0	1	1	0	0	2	1	0	1	0	0	2	1	1	0	6	4	7	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	3	0	1	0	1	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS		Defending Against Neural Fake News	http://papers.nips.cc/paper/9106-defending-against-neural-fake-news	Abeba	done	2			2	generation	2	3	0	0	0	4	0	0	0	0	1	0	1	2	2	1	2	0	0	0	0	0	1	0	1	3	0	0	1	0	0	0	0	0	2	0	0	0	1	4	0	2	0	6	0	0	1	1	2	0	1	5	3	0	0	0	0	0	1	0	0	0	6	0	1	2	0	0	0	0	0	0	0	0	0
2019	NeurIPS		Defending Against Neural Fake News	http://papers.nips.cc/paper/9106-defending-against-neural-fake-news	Michelle	done			societal need is defined as developing mechanisms to combat neural fake news. I think they could have more rigorously justified the existence of neural fake news (they justify fake news rigorously but not neural fake news) but overall I think the societal need is a huge emphasis	4	generation / application	2	2	0	0	2	4	3	0	0	0	5	1	2	4	1	1	2	0	0	0	0	0	1	0	2	4	0	1	1	0	0	0	0	0	2	0	0	6	1	3	1	5	0	5	0	0	1	1	1	3	1	11	1	0	0	0	1	0	0	5	0	2	3	0	0	5	0	0	0	0	0	0	0	1	0
																																																																																						
2019	NeurIPS	not top 12	Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks	http://papers.nips.cc/paper/9266-generalization-bounds-of-stochastic-gradient-descent-for-wide-and-deep-neural-networks.pdf	Ravit	done	1			1	Understanding	0	0	0	2	0	0	0	2	0	0	0	0	2	0	0	0	0	0	4	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	1	0	9	0	0	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS	not top 12	Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks	http://papers.nips.cc/paper/9266-generalization-bounds-of-stochastic-gradient-descent-for-wide-and-deep-neural-networks.pdf	Michelle																																																																																	
																																																																																						
2019	NeurIPS	not top 12	Adversarial Training and Robustness for Multiple Perturbations	http://papers.nips.cc/paper/8821-adversarial-training-and-robustness-for-multiple-perturbations.pdf	Dallas	done	1		"a nod to ""cyber-physical systems"", but only superficial"	2	"understanding, defenses"	0	5	5	18	0	34	0	3	5	0	7	0	0	0	0	3	0	0	0	0	0	0	0	0	0	7	0	0	5	0	0	1	0	0	0	0	0	2	0	6	0	4	0	0	0	0	0	0	0	1	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	1	1	0	0	0
2019	NeurIPS	not top 12	Adversarial Training and Robustness for Multiple Perturbations	http://papers.nips.cc/paper/8821-adversarial-training-and-robustness-for-multiple-perturbations.pdf	Ria																																																																																	
																																																																																						
2019	NeurIPS	not top 12	Unlabeled Data Improves Adversarial Robustness	http://papers.nips.cc/paper/9298-unlabeled-data-improves-adversarial-robustness	Ravit	done	2			2	Defenses	0	0	0	0	1	2	0	0	0	0	0	0	7	0	0	1	4	0	1	0	0	0	0	0	8	10	0	4	0	0	0	0	2	0	1	0	1	3	0	0	0	2	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS	not top 12	Unlabeled Data Improves Adversarial Robustness	http://papers.nips.cc/paper/9298-unlabeled-data-improves-adversarial-robustness	Dallas	done		done	possibly a good candidate for quoting	1	Defenses	0	0	0	0	1	25	0	6	9	0	11	0	3	0	0	1	3	0	0	0	0	0	0	0	0	14	0	4	0	0	0	0	7	0	1	0	1	5	0	0	0	2	0	0	0	0	0	0	0	0	1	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	NeurIPS	not top 12	BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling	http://papers.nips.cc/paper/8882-biva-a-very-deep-hierarchy-of-latent-variables-for-generative-modeling.pdf	Ravit	done	2			2	Generation	0	0	0	0	6	0	5	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	10	0	0	4	0	0	0	0	0	0	1	0	1	2	1	0	0	3	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	NeurIPS	not top 12	BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling	http://papers.nips.cc/paper/8882-biva-a-very-deep-hierarchy-of-latent-variables-for-generative-modeling.pdf	Willie	done				1	Generation	0	2	0	0	4	0	5	0	0	1	1	0	0	0	0	1	0	1	0	0	0	0	0	0	12	1	0	3	2	0	0	0	5	0	0	0	0	7	0	0	0	0	0	0	0	0	0	0	0	0	2	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0
																																																																																						
2018	NeurIPS		Glow: Generative Flow with Invertible 1x1 Convolutions	http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions	Abeba	done	2			1	Generation	0	3	2	4	1	2	2	0	0	2	3	2	2	0	2	0	3	1	1	0	3	0	0	0	2	2	0	1	3	0	1	2	1	0	0	0	0	2	0	1	0	0	3	0	1	0	0	0	6	1	0	0	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Glow: Generative Flow with Invertible 1x1 Convolutions	http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions	Ria	done				2	Generation	0	4	2	8	0	3	2	0	0	0	3	1	0	0	0	0	5	0	0	0	5	0	0	0	1	2	0	2	4	0	1	2	2	0	0	0	0	1	0	0	0	0	3	0	0	0	0	0	5	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	1	0
																																																																																						
2018	NeurIPS		Neural Ordinary Differential Equations	http://papers.nips.cc/paper/7892-neural-ordinary-differential-equations.pdf	Abeba	done	2			1	Generation	0	4	3	0	4	0	1	2	0	1	1	0	3	1	0	0	1	0	0	0	0	1	0	1	0	5	0	0	2	0	3	2	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	1	1	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Neural Ordinary Differential Equations	http://papers.nips.cc/paper/7892-neural-ordinary-differential-equations.pdf	Dallas	done		done		1	modeling	0	3	1	0	2	0	0	2	1	1	1	0	1	0	0	0	1	0	0	0	0	1	0	1	0	5	0	0	2	0	2	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	1	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2
																																																																																						
2018	NeurIPS		Hierarchical Graph Representation Learning with Differentiable Pooling	http://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf	Dallas	done	2		"unusually plain example; mostly focuses on ML-specific priorities (end-to-end training, heirarchical representations), with some of the usual SOTA + flexibility thrown in"	1	Classification	0	3	1	3	8	0	0	0	0	0	2	0	0	0	0	0	0	0	2	0	0	0	0	0	0	2	0	4	1	0	0	0	0	0	2	0	0	1	0	2	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Hierarchical Graph Representation Learning with Differentiable Pooling	http://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf	Michelle	done				1	Classification	0	4	1	2	5	0	0	0	0	0	2	0	0	0	0	1	0	0	2	0	0	0	0	0	0	2	0	4	1	0	0	0	0	0	2	1	0	4	3	4	0	0	0	0	0	0	0	0	0	0	0	3	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2018	NeurIPS		Isolating Sources of Disentanglement in Variational Autoencoders	http://papers.nips.cc/paper/7527-isolating-sources-of-disentanglement-in-variational-autoencoders	Abeba	done	2		"I found it difficult to categorize this paper as it seems to be engaged in proposing a framework for representing information that bypasses ""calssifiers"""	1	Understanding(?) Classification(?) 	0	4	2	2	0	2	0	0	0	0	2	3	4	0	0	0	0	0	1	1	0	0	0	3	1	0	0	1	2	0	0	0	0	0	0	1	0	1	1	0	0	0	0	0	0	0	1	1	1	0	0	0	0	0	1	3	0	0	0	0	0	0	0	0	1	0	0	0	0	1	0	0	0	0	0
2018	NeurIPS		Isolating Sources of Disentanglement in Variational Autoencoders	http://papers.nips.cc/paper/7527-isolating-sources-of-disentanglement-in-variational-autoencoders	Willie	done				1	Disentanglement	0	3	4	3	0	2	0	0	1	0	3	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	1	0	0	0	2	0	0	0	0	2	0	0	0	1	0	0	0	0	0	0	0	1	0	0	0	0	1	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0
																																																																																						
2018	NeurIPS		PointCNN: Convolution On X-Transformed Points	http://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points.pdf	Ravit	done	1			1	Unsure	0	0	1	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	1	0	0	0	0	0	1	0	0	3	0	0	0	0	0	0	2	0	3	0	0	0	0	2	0	0	0	0	0	0	0	1	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		PointCNN: Convolution On X-Transformed Points	http://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points.pdf	Michelle - done but not pasted?																																																																																	
																																																																																						
2018	NeurIPS		Neural Tangent Kernel: Convergence and Generalization in Neural Networks	http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks	Ravit	done	2			1	Understanding	0	0	0	0	0	0	0	7	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	4	0	0	14	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Neural Tangent Kernel: Convergence and Generalization in Neural Networks	http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks	Ria	done				1	Understanding	0	2	2	4	0	0	0	26	9	0	3	0	1	0	0	0	0	0	0	0	0	2	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	11	0	0	26	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
																																																																																						
2018	NeurIPS		Video-to-Video Synthesis	http://papers.nips.cc/paper/7391-video-to-video-synthesis	Ria	done	2			1	"Generation (""Video synthesis"")"	0	5	0	5	2	1	12	1	0	1	3	5	0	2	0	0	5	0	1	0	0	1	0	0	3	0	0	2	0	0	0	1	0	0	0	0	0	1	0	5	0	1	0	0	1	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	2	2	0
2018	NeurIPS		Video-to-Video Synthesis	http://papers.nips.cc/paper/7391-video-to-video-synthesis	Ravit	done			"This paper really should discuss negative potential. Their model gives the owner the power to change things in a video, e.g. replace a building with a tree. This capability could be used in many bad ways, e.g. creating fake news, falisifying evidence. "	1	Generation	0	2	0	0	3	0	8	0	0	0	3	0	0	2	1	0	0	0	1	0	0	0	0	0	3	0	0	3	2	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	2	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2018	NeurIPS		Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data	http://papers.nips.cc/paper/8038-learning-overparameterized-neural-networks-via-stochastic-gradient-descent-on-structured-data	Willie	done	1			1	Understanding	0	0	0	7	0	0	0	6	4	2	3	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	1	3	0	0	0	8	0	0	0	0	0	0	0	0	0	4	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data	http://papers.nips.cc/paper/8038-learning-overparameterized-neural-networks-via-stochastic-gradient-descent-on-structured-data	Dallas																																																																																	
																																																																																						
2018	NeurIPS		Adversarially Robust Generalization Requires More Data	http://papers.nips.cc/paper/7749-adversarially-robust-generalization-requires-more-data	Ria	done	2		"I annotated this early on, so my methodology might be not as fine-tuned. If necessary, I can reannotate."	3	Understanding	0	0	0	18	0	42	0	19	0	0	10	1	1	0	0	0	0	0	0	0	1	0	2	0	1	14	4	2	0	0	0	10	0	0	0	1	0	0	0	6	0	16	0	1	1	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	8	2	0	0
2018	NeurIPS		Adversarially Robust Generalization Requires More Data	http://papers.nips.cc/paper/7749-adversarially-robust-generalization-requires-more-data	Willie	done				2	Understanding	0	0	3	19	7	39	0	6	7	0	6	0	0	0	0	0	0	0	0	0	0	0	0	0	1	14	0	2	0	0	0	0	10	3	0	0	1	10	0	0	0	1	0	1	0	0	0	0	0	0	1	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	32	0	0	0
																																																																																						
2018	NeurIPS		How Does Batch Normalization Help Optimization?	http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf	Ria	done	2			1	Understanding	0	0	0	3	0	1	0	7	0	0	1	0	1	0	0	0	0	0	0	0	0	0	1	0	4	0	0	0	0	0	0	0	0	0	5	4	0	2	3	0	0	32	2	4	2	0	0	0	0	0	0	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	4
2018	NeurIPS		How Does Batch Normalization Help Optimization?	http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf	Abeba	done				1	understanding	0	0	0	2	0	1	0	3	2	0	2	1	4	1	0	0	1	0	1	0	2	0	1	0	6	0	0	0	0	0	0	0	0	0	6	5	1	1	0	1	0	15	4	3	0	0	0	0	0	0	0	1	0	1	1	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	4
																																																																																						
2018	NeurIPS		Adversarial Logit Pairing	https://arxiv.org/abs/1803.06373	Ravit	done	2			2	Defenses	0	0	0	0	0	2	0	0	1	0	0	0	4	0	0	2	6	0	0	0	0	0	0	0	2	4	0	6	0	0	0	0	0	0	3	0	0	1	0	0	0	2	0	0	0	0	0	0	0	0	0	1	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		Adversarial Logit Pairing	https://arxiv.org/abs/1803.06373	Dallas	done		done	GOOD example	2			0	0	0	0	3	0	0	1	0	0	0	2	0	0	2	7	0	0	0	0	0	0	0	0	5	0	8	0	0	0	0	0	0	3	0	0	1	0	2	0	2	0	0	0	0	0	1	0	0	0	1	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2018	NeurIPS		"Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers"	http://papers.nips.cc/paper/8847-learning-and-generalization-in-overparameterized-neural-networks-going-beyond-two-layers	Ravit	done	2			2	Understanding	0	6	0	6	3	0	0	6	0	0	0	0	5	0	0	0	0	0	0	0	0	0	0	0	1	3	0	0	2	1	0	0	0	0	0	1	1	1	1	0	0	13	0	0	0	0	0	0	0	0	0	5	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS		"Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers"	http://papers.nips.cc/paper/8847-learning-and-generalization-in-overparameterized-neural-networks-going-beyond-two-layers	Willie	done				1	Understanding	0	4	2	11	2	0	0	8	12	1	4	0	0	0	0	0	0	0	0	0	0	0	0	0	3	3	0	0	6	0	0	2	0	0	0	0	1	13	1	0	0	5	0	0	1	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2018	NeurIPS	not top 12	Data-Efficient Hierarchical Reinforcement Learning	http://papers.nips.cc/paper/7591-data-efficient-hierarchical-reinforcement-learning	Ravit	done	1			3	Robotics	0	1	2	0	0	1	0	0	0	0	0	0	1	0	0	1	0	2	7	0	0	0	0	1	5	0	0	1	1	3	0	6	0	0	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	NeurIPS	not top 12	Data-Efficient Hierarchical Reinforcement Learning	http://papers.nips.cc/paper/7591-data-efficient-hierarchical-reinforcement-learning	Ria																																																																																	
																																																																																						
2009	NeurIPS		Rethinking LDA: Why Priors Matter	http://papers.nips.cc/paper/3854-rethinking-lda-why-priors-matter	Dallas	done	2		"Contains a fun meta sentence that, ""For example, the words “model,” “data,” and “algorithm” are likely to appear in every paper published in a machine learning conference"""	3	Understanding	0	0	3	0	0	3	0	0	0	1	2	1	1	0	0	4	0	0	0	0	0	0	0	0	5	0	0	0	4	1	0	0	0	0	0	0	0	2	1	1	0	1	0	0	1	0	1	0	0	0	0	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Rethinking LDA: Why Priors Matter	http://papers.nips.cc/paper/3854-rethinking-lda-why-priors-matter	Ravit	done			I think this paper does a good job connecting to social needs because it emphasizes the needs of the users of the models and uses it as a measure to evaluate their model	4	"I agree that a part of it is understanding, but I think there is something more that I'm not sure what to call"	0	0	0	0	0	2	0	0	0	0	0	0	2	0	0	1	1	0	0	0	0	0	0	0	5	0	0	0	2	0	0	0	0	0	0	0	0	1	0	0	0	1	0	0	1	0	0	4	0	0	0	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	NeurIPS		Replicated Softmax: an Undirected Topic Model	http://papers.nips.cc/paper/3856-replicated-softmax-an-undirected-topic-model	Dallas	done	2			1	Representation Learning	0	2	1	3	3	0	0	1	0	1	2	0	0	0	0	0	4	0	1	0	1	1	0	2	0	8	0	0	2	0	0	0	0	0	0	0	0	3	0	5	0	0	0	0	3	0	0	0	0	0	1	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Replicated Softmax: an Undirected Topic Model	http://papers.nips.cc/paper/3856-replicated-softmax-an-undirected-topic-model	Ria	done				1	Topic modeling (and seconday goal of generation)	0	3	1	3	7	0	1	1	0	1	3	0	0	0	0	0	2	0	0	0	2	2	0	1	2	7	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	0	1
																																																																																						
2009	NeurIPS		Guaranteed Rank Minimization via Singular Value Projection	http://papers.nips.cc/paper/3904-guaranteed-rank-minimization-via-singular-value-projection.pdf	Dallas	done	2		perfect example of a (mostly) theoretical paper; closest thing to a societal need is a mention of image compression	1	rank minimization	0	6	4	6	0	4	0	11	20	1	5	0	0	0	0	0	0	0	1	0	1	1	0	0	6	5	0	0	4	3	0	0	0	0	0	0	0	5	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2
2009	NeurIPS		Guaranteed Rank Minimization via Singular Value Projection	http://papers.nips.cc/paper/3904-guaranteed-rank-minimization-via-singular-value-projection.pdf	Willie	done				1	"understanding, rank minimization"	0	0	3	0	0	4	0	3	8	0	6	0	0	0	0	0	0	0	0	0	0	0	0	0	3	5	0	1	6	0	0	5	0	0	0	0	0	9	0	0	0	0	0	0	2	0	0	0	0	0	0	2	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	NeurIPS		Multi-Label Prediction via Compressed Sensing	http://papers.nips.cc/paper/3824-multi-label-prediction-via-compressed-sensing.pdf	Dallas	done	2		"unusual in that it doesn't mention empirical evidence in the intro, despite having experiments; There is no conclusion section;  interesting for the way it frames potential applicatoin: ""Suppose we have a large database of images, and we want to learn to predict who or what is in anygiven one."" [but without any hint of what sorts of things we want to identify["	1	Classification	0	2	1	1	0	4	0	9	6	1	2	0	0	0	0	2	4	0	5	0	0	0	0	0	0	1	0	0	4	0	0	0	1	0	0	0	0	4	5	0	0	0	0	0	3	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Multi-Label Prediction via Compressed Sensing	http://papers.nips.cc/paper/3824-multi-label-prediction-via-compressed-sensing.pdf	Abeba	done				1	Classification	0	2	1	0	0	4	0	8	3	0	1	0	1	0	0	2	5	0	5	0	0	0	0	1	0	1	0	0	2	0	0	3	3	0	1	0	2	1	4	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	NeurIPS		Kernel Methods for Deep Learning	http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf	Willie	done	2			0	Classification	0	4	3	0	2	0	0	0	0	0	5	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	1	0	2	0	1	0	0	0	0	0	7	5	1	0	0	0	0	1	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0				
2009	NeurIPS		Kernel Methods for Deep Learning	http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf	Ravit	done			"This paper is a good example for how accuracy can be politically loaded. On the surface, the paper is interested in getting good performace and easy traning. However, it flags right at the beginning that it is interested in circumstances in which large nueral netwroks have good perfromance, which may be circumstances that are more relevant to those with more resources, sufficient to support such large netwroks"	1			3	0	0	1	0	0	0	0	0	3	0	1	0	0	0	2	0	0	0	0	0	0	0	1	0	0	1	0	0	0	0	0	0	0	1	0	2	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	3	0	0
																																																																																						
2009	NeurIPS		Nonparametric Latent Feature Models for Link Prediction	http://papers.nips.cc/paper/3846-nonparametric-latent-feature-models-for-link-prediction	Willie	done	1			3	Classification	0	7	0	1	8	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	3	0	0	0	1	0	32	0	0	0	0	0	0	0	0	0	0	0	0	2	2	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0				
2009	NeurIPS		Nonparametric Latent Feature Models for Link Prediction	http://papers.nips.cc/paper/3846-nonparametric-latent-feature-models-for-link-prediction	Ria																																																																																	
																																																																																						
2009	NeurIPS		Measuring Invariances in Deep Networks	http://papers.nips.cc/paper/3790-measuring-invariances-in-deep-networks.pdf	Michelle	done	1		should reannotate to include the newer values	1	"Evaluation, Understanding(?)"	0	0	0	1	3	23	0	0	1	0	4	1	0	0	0	1	0	1	0	0	0	0	0	2	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	5	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0				
2009	NeurIPS		Measuring Invariances in Deep Networks	http://papers.nips.cc/paper/3790-measuring-invariances-in-deep-networks.pdf	Dallas								0	0	3	2	7	0	0	1	0	5	0	0	0	0	1	0	1	2	0	0	0	0	2	3	0	0	0	0	0	0	0	0	0	0	1	0	5	0	1	0	3	0	0	0	0	0	0	0	0	0	2	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	NeurIPS		3D Object Recognition with Deep Belief Nets	http://papers.nips.cc/paper/3872-3d-object-recognition-with-deep-belief-nets	Willie	done	2			1	Classifcation	0	1	0	1	1	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	5	2	0	1	0	1	1	0	4	0	0	0	0	6	1	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		3D Object Recognition with Deep Belief Nets	http://papers.nips.cc/paper/3872-3d-object-recognition-with-deep-belief-nets	Abeba	done				1	Classifcation	0	2	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	2	1	1	0	0	0	1	5	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	NeurIPS	Correct title for link: Analysis of Kernel Mean Matching under Covariate Shift	Covariate Shift by Kernel Mean Matching	https://icml.cc/2012/papers/330.pdf	Abeba	done	1		JUST NOTICED THIS IS THE WRONG LINK!	1	Understanding	0	0	2	1	1	0	0	2	0	4	1	1	1	0	0	0	0	0	0	0	0	0	3	0	0	0	8	0	0	0	0	0	0	0	4	0	1	0	1	2	0	3	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Covariate Shift by Kernel Mean Matching	https://icml.cc/2012/papers/330.pdf	Ravit - ***																																																																																	
																																																																																						
2009	NeurIPS		Slow Learners are Fast	http://papers.nips.cc/paper/3888-slow-learners-are-fast	Abeba	done	1			1	Creation (of a new system?) 	0	4	0	0	0	1	0	0	3	0	3	0	1	0	0	1	2	1	0	0	0	0	0	0	1	0	0	0	3	2	3	0	0	0	0	0	0	1	2	2	0	0	0	0	0	0	0	0	6	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Slow Learners are Fast	http://papers.nips.cc/paper/3888-slow-learners-are-fast	Ria																																																																																	
																																																																																						
2009	NeurIPS		Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models	http://papers.nips.cc/paper/3881-efficient-large-scale-distributed-training-of-conditional-maximum-entropy-models	Michelle	done	1			1	Distributed training	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models	http://papers.nips.cc/paper/3881-efficient-large-scale-distributed-training-of-conditional-maximum-entropy-models	Dallas																																																																																	
																																																																																						
2009	NeurIPS		Learning Non-Linear Combinations of Kernels	http://papers.nips.cc/paper/3692-learning-non-linear-combinations-of-kernels.pdf	Abeba	done	1			1	Optimization (?) 	0	0	2	1	0	0	0	0	0	0	4	0	5	0	0	0	0	0	5	0	0	0	0	0	8	0	0	0	4	0	0	0	0	0	3	1	0	1	0	1	0	1	6	1	0	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0
2009	NeurIPS		Learning Non-Linear Combinations of Kernels	http://papers.nips.cc/paper/3692-learning-non-linear-combinations-of-kernels.pdf	Willie																																																																																	
																																																																																						
2008	NeurIPS		Clustered Multi-Task Learning: A Convex Formulation	http://papers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-formulation.pdf	Ravit	done	1			1	Prediction (?)	0	1	0	0	1	0	0	0	0	0	2	0	0	0	0	0	0	2	0	0	0	0	0	0	3	0	0	0	2	0	0	0	0	0	0	0	3	2	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		Clustered Multi-Task Learning: A Convex Formulation	http://papers.nips.cc/paper/3499-clustered-multi-task-learning-a-convex-formulation.pdf	Ria																																																																																	
																																																																																						
2008	NeurIPS		Privacy-preserving logistic regression	http://papers.nips.cc/paper/3486-privacy-preserving-logistic-regression.pdf	Ravit	done	2			4	Not sure	0	1	0	0	4	0	0	1	3	0	2	0	0	0	0	0	0	0	1	0	0	0	0	0	3	0	0	0	2	0	0	0	0	0	0	0	0	2	0	0	0	3	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	16	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		Privacy-preserving logistic regression	http://papers.nips.cc/paper/3486-privacy-preserving-logistic-regression.pdf	Dallas	done		done		3	classification	0	1	0	0	3	0	0	4	5	0	3	0	0	0	0	0	0	0	1	0	0	0	0	0	3	0	0	0	2	0	0	0	0	0	0	0	0	9	2	0	0	2	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	19	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2008	NeurIPS		Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity	http://papers.nips.cc/paper/3494-gaussian-process-factor-analysis-for-low-dimensional-single-trial-analysis-of-neural-population-activity.pdf	Michelle	done	1			3	Other (Neural Analysis)	0	1	4	1	1	1	0	0	0	0	0	0	0	3	0	0	0	0	0	2	0	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	4	2	3	0	0	1	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity	http://papers.nips.cc/paper/3494-gaussian-process-factor-analysis-for-low-dimensional-single-trial-analysis-of-neural-population-activity.pdf	Willie																																																																																	
																																																																																						
2008	NeurIPS		The Recurrent Temporal Restricted Boltzmann Machine	http://papers.nips.cc/paper/3567-the-recurrent-temporal-restricted-boltzmann-machine	Ravit	done	2			1	Generation	0	0	0	0	2	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	3	2	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		The Recurrent Temporal Restricted Boltzmann Machine	http://papers.nips.cc/paper/3567-the-recurrent-temporal-restricted-boltzmann-machine	Abeba	done				1	generation	0	1	0	0	1	0	3	1	0	0	0	0	0	0	0	0	0	0	0	0	5	0	0	0	1	2	0	0	0	0	0	0	0	0	0	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0
																																																																																						
2008	NeurIPS		Translated Learning: Transfer Learning across Different Feature Spaces	http://papers.nips.cc/paper/3492-translated-learning-transfer-learning-across-different-feature-spaces	Willie	done (abeba)	1			3	transfer learning	0	4	1	0	2	0	0	6	0	1	5	6	0	0	0	0	1	0	2	0	0	0	0	0	3	0	0	2	0	0	0	10	8	0	2	1	3	0	4	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		Translated Learning: Transfer Learning across Different Feature Spaces	http://papers.nips.cc/paper/3492-translated-learning-transfer-learning-across-different-feature-spaces	Michelle																																																																																	
																																																																																						
2008	NeurIPS		Domain Adaptation with Multiple Sources	http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources	Ria	done (abeba)	1			1	understanding(?) theory testing (?) 	0	2	4	5	0	0	0	2	11	0	5	2	1	0	0	1	1	0	0	0	0	0	0	0	1	0	0	0	0	1	1	2	2	0	0	1	1	2	0	1	0	0	0	0	1	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		Domain Adaptation with Multiple Sources	http://papers.nips.cc/paper/3550-domain-adaptation-with-multiple-sources	Dallas																																																																																	
																																																																																						
2008	NeurIPS		"On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization"	http://papers.nips.cc/paper/3510-on-the-complexity-of-linear-prediction-risk-bounds-margin-bounds-and-regularization	Ria	done	1			1	Learning(?) Generalization(?)	0	2	2	14	0	0	0	7	4	0	2	1	3	0	0	0	0	0	3	0	0	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	13	0	7	0	0	1	0	0	0	0	0	0	1	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	NeurIPS		"On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization"	http://papers.nips.cc/paper/3510-on-the-complexity-of-linear-prediction-risk-bounds-margin-bounds-and-regularization	Willie																																																																																	
																																																																																						
2008	NeurIPS		Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning	http://papers.nips.cc/paper/3418-exploring-large-feature-spaces-with-hierarchical-multiple-kernel-learning	Ria		1																																																																															
2008	NeurIPS		Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning	http://papers.nips.cc/paper/3418-exploring-large-feature-spaces-with-hierarchical-multiple-kernel-learning	Abeba	done				1	learning (?) prediction (?)	0	1	0	0	1	0	0	0	0	0	1	1	1	0	0	1	3	0	0	0	1	1	0	0	9	0	0	1	3	1	0	1	0	0	0	0	2	2	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2008	NeurIPS		Nonrigid Structure from Motion in Trajectory Space	http://papers.nips.cc/paper/3493-nonrigid-structure-from-motion-in-trajectory-space.pdf	Dallas	done	1		explicitly connects itself to facial motion estimation	1	3d structure estimation from video	0	5	0	7	1	0	0	3	0	1	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	2	0	0	0	0	0	0	0	0	3	1	1	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0
2008	NeurIPS		Nonrigid Structure from Motion in Trajectory Space	http://papers.nips.cc/paper/3493-nonrigid-structure-from-motion-in-trajectory-space.pdf	Ravit																																																																																	
																																																																																						
2008	NeurIPS		Online Metric Learning and Fast Similarity Search	http://papers.nips.cc/paper/3446-online-metric-learning-and-fast-similarity-search.pdf	Dallas	done	1		"mentions ""image search applications"", which seems borderline as a societal need"	1	metric learning	0	8	1	7	2	0	0	2	8	1	4	0	0	0	0	3	4	0	0	0	0	0	0	1	6	3	0	1	4	0	0	0	0	0	2	1	0	10	0	5	0	0	0	0	1	0	0	0	0	0	0	4	0	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	11
2008	NeurIPS		Online Metric Learning and Fast Similarity Search	http://papers.nips.cc/paper/3446-online-metric-learning-and-fast-similarity-search.pdf	Ria																																																																																	
																																																																																						
2008	NeurIPS		Local Gaussian Process Regression for Real Time Online Model Learning	http://papers.nips.cc/paper/3403-local-gaussian-process-regression-for-real-time-online-model-learning	Dallas	done	1		unusually modest paper; good example of generic application: unspecified deployment of robotics	1	approximating inverse dynamics	0	3	1	4	2	0	0	0	0	3	3	0	0	1	0	4	2	0	0	0	0	1	0	0	5	8	0	2	1	0	0	0	0	0	0	0	0	5	3	1	0	0	0	0	0	0	0	0	0	0	2	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	1	6
2008	NeurIPS		Local Gaussian Process Regression for Real Time Online Model Learning	http://papers.nips.cc/paper/3403-local-gaussian-process-regression-for-real-time-online-model-learning	Willie																																																																																	
																																																																																						
2008	NeurIPS		Deflation Methods for Sparse PCA	http://papers.nips.cc/paper/3575-deflation-methods-for-sparse-pca.pdf	Dallas	done	2	done	extremely technically narrow; main use case would be in data exploration	1	representation learning	0	7	0	7	0	0	0	4	1	2	3	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	2	0	4	0	0	0	0	1	0	0	0	0	0	0	3	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
2008	NeurIPS		Deflation Methods for Sparse PCA	http://papers.nips.cc/paper/3575-deflation-methods-for-sparse-pca.pdf	Abeba	done				1	not sure 	0	1	0	6	0	0	0	5	1	1	3	0	3	0	0	0	0	0	1	0	0	0	0	0	2	0	0	0	0	0	0	0	0	1	0	0	1	1	0	2	0	0	1	0	2	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	ICML		EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks	http://arxiv.org/abs/1905.11946	Willie	done	1			1	"Classification, Understanding"	0	0	4	2	1	0	0	1	0	0	4	0	0	0	0	0	0	0	0	2	0	0	0	0	2	10	0	5	11	0	0	0	0	0	2	0	0	0	0	0	0	3	0	0	0	0	2	1	0	1	15	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0			
2019	ICML		EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks	http://arxiv.org/abs/1905.11946	Ravit																																																																																	
																																																																																						
2019	ICML		Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks	http://proceedings.mlr.press/v97/arora19a/arora19a-supp.pdf	Willie	done	1			1	Understanding	0	0	1	18	14	0	0	12	5	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	3	9	0	0	3	0	0	0	0	0	0	0	1	17	0	0	0	3	0	0	0	0	0	0	0	0	1	5	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0			
2019	ICML		Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks	http://proceedings.mlr.press/v97/arora19a/arora19a-supp.pdf	Michelle																																																																																	
																																																																																						
2019	ICML		Certified Adversarial Robustness via Randomized Smoothing	https://arxiv.org/pdf/1902.02918.pdf	Willie	done	2			1	"Classification Understanding, Defenses"	0	0	2	0	8	25	0	1	12	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	0	1	0	0	0	0	0	0	0	0	0	6	0	0	0	0	0	0	0	0	0	0	0	1	7	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	11			
2019	ICML		Certified Adversarial Robustness via Randomized Smoothing	https://arxiv.org/pdf/1902.02918.pdf	Dallas	done		done	"OK example that combines theory, empirical, robustness, accuracy, and scale"	1	"Classification, Understanding, Defenses"	0	0	1	0	4	13	0	10	9	0	6	0	0	0	0	0	0	0	0	0	0	1	0	0	0	6	0	1	0	0	0	0	0	0	0	0	0	5	0	2	0	0	0	0	0	0	1	0	0	1	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	ICML		Theoretically Principled Trade-off between Robustness and Accuracy	http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf	Willie	done	2			3	"Defenses, Classification, Understanding"	0	0	4	2	0	18	0	4	8	0	6	0	0	0	0	0	0	0	0	0	0	0	0	0	2	18	0	7	0	0	0	0	0	0	1	0	1	10	0	0	0	1	0	0	0	0	0	0	0	0	4	5	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	14			
2019	ICML		Theoretically Principled Trade-off between Robustness and Accuracy	http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf	Abeba	done				2	"defenses, theoretical understanding, classification"	0	3	0	3	0	19	0	1	11	1	1	5	2	0	0	0	1	0	2	0	0	0	0	0	4	12	0	4	0	0	0	0	0	0	1	0	1	0	0	1	0	1	2	0	0	0	0	0	0	0	1	2	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	9	0	0	0
																																																																																						
2019	ICML		MASS: Masked Sequence to Sequence Pre-training for Language Generation	https://icml.cc/media/Slides/icml/2019/104(13-11-00)-13-12-00-4889-mass_masked_se.pdf	Abeba	done	1			1	generation	0	1	0	3	3	0	0	0	0	0	3	0	1	0	0	0	2	1	0	0	0	0	0	0	2	2	4	4	0	2	0	6	0	0	2	2	1	0	0	0	0	2	4	0	0	0	0	4	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		MASS: Masked Sequence to Sequence Pre-training for Language Generation	https://icml.cc/media/Slides/icml/2019/104(13-11-00)-13-12-00-4889-mass_masked_se.pdf	Ravit																																																																																	
																																																																																						
2019	ICML		Simplifying Graph Convolutional Networks	http://arxiv.org/abs/1902.07153	Abeba	done	1			1	classification	0	0	15	0	1	0	0	0	1	0	2	0	1	0	0	0	0	0	0	0	0	0	0	0	7	2	0	4	3	1	0	1	0	0	2	0	0	1	0	0	0	2	1	0	0	0	0	0	0	1	1	4	0	0	0	2	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0
2019	ICML		Simplifying Graph Convolutional Networks	http://arxiv.org/abs/1902.07153	Ria																																																																																	
																																																																																						
2019	ICML		Do ImageNet Classifiers Generalize to ImageNet?	http://people.csail.mit.edu/ludwigs/papers/imagenet.pdf	Abeba	done	1			2	"classification, generalization"	0	1	0	8	0	3	0	0	0	2	11	1	0	0	1	0	0	1	0	0	1	0	0	0	7	28	0	1	0	0	0	0	1	0	1	0	5	0	0	4	4	4	5	1	0	5	0	0	0	0	0	1	10	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		Do ImageNet Classifiers Generalize to ImageNet?	http://people.csail.mit.edu/ludwigs/papers/imagenet.pdf	Michelle																																																																																	
																																																																																						
2019	ICML		Adversarial Examples Are a Natural Consequence of Test Error in Noise	https://icml.cc/media/Slides/icml/2019/104(12-11-00)-12-11-25-4381-adversarial_exa.pdf	Abeba	done	1			1	defenses	0	1	0	1	0	24	1	0	1	0	1	0	2	0	2	0	0	0	1	0	0	0	0	0	6	0	1	1	0	0	0	0	0	0	1	2	0	0	4	0	0	0	10	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	1	0	0	0	0	0	0	0	0	0	0
2019	ICML		Adversarial Examples Are a Natural Consequence of Test Error in Noise	https://icml.cc/media/Slides/icml/2019/104(12-11-00)-12-11-25-4381-adversarial_exa.pdf	Ria - old																																																																																	
																																																																																						
2019	ICML		NAS-Bench-101: Towards Reproducible Neural Architecture Search	https://icml.cc/media/Slides/icml/2019/halla(12-14-00)-12-14-20-4950-nas-bench-101_.pdf	Michelle	done	1		unsure about justification score - does researcher / low resource accessibility count without tying it to more societal aspects of power centralization?	2	evaluation / dataset creation	0	7	0	1	2	0	0	0	0	0	3	0	0	0	0	2	2	1	0	0	1	0	0	0	1	3	0	2	8	0	0	0	0	1	0	0	0	1	0	0	0	2	0	0	0	4	0	4	0	5	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		NAS-Bench-101: Towards Reproducible Neural Architecture Search	https://icml.cc/media/Slides/icml/2019/halla(12-14-00)-12-14-20-4950-nas-bench-101_.pdf	Ria																																																																																	
																																																																																						
2019	ICML		Using Pre-Training Can Improve Model Robustness and Uncertainty	https://icml.cc/media/Slides/icml/2019/grandball(11-11-00)-11-12-05-4737-using_pre-train.pdf	Michelle	done	2			1	Understanding	0	0	0	1	0	9	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	10	5	1	7	0	1	0	1	0	0	0	0	0	4	0	0	0	4	3	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		Using Pre-Training Can Improve Model Robustness and Uncertainty	https://icml.cc/media/Slides/icml/2019/grandball(11-11-00)-11-12-05-4737-using_pre-train.pdf	Dallas	done		done		1	Understanding	0	0	0	1	0	11	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	8	4	0	7	0	2	0	1	0	0	0	0	0	5	0	0	0	2	3	0	1	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2019	ICML		Error Feedback Fixes SignSGD and other Gradient Compression Schemes	https://arxiv.org/pdf/1901.09847v1.pdf	Michelle	done	1			1	Training (?)	0	0	4	6	0	0	0	8	7	1	4	4	0	0	0	1	3	0	0	0	0	0	0	0	2	0	1	0	6	1	0	0	0	0	0	0	1	3	0	4	0	4	0	1	1	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		Error Feedback Fixes SignSGD and other Gradient Compression Schemes	https://arxiv.org/pdf/1901.09847v1.pdf	Willie																																																																																	
																																																																																						
2019	ICML		Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication	https://icml.cc/media/Slides/icml/2019/103(11-14-00)-11-15-05-4671-decentralized_s.pdf	Ravit	done	2			3	not sure	0	6	0	0	0	0	0	4	0	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	1	1	0	2	2	0	0	1	0	0	0	0	0	2	0	0	0	0	0	0	2	0	0	0	0	0	3	1	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2019	ICML		Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication	https://icml.cc/media/Slides/icml/2019/103(11-14-00)-11-15-05-4671-decentralized_s.pdf	Abeba	done				2	not sure	0	7	0	0	2	0	0	6	2	0	4	0	1	0	0	0	2	1	1	0	1	1	0	0	3	4	0	2	2	0	0	1	0	0	0	0	1	4	0	0	0	0	1	0	2	0	0	0	1	0	2	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
																																																																																						
2018	ICML		Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples	http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf	Ria	done	1			2	defenses	0	6	0	0	0	4	0	2	0	1	0	4	2	0	0	0	0	0	1	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	2	0	3	0	1	0	3	0	1	3	0	0	0	0	1	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0
2018	ICML		Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples	http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf	Ravit																																																																																	
																																																																																						
2018	ICML		Self-Attention Generative Adversarial Networks	http://proceedings.mlr.press/v97/zhang19d/zhang19d.pdf	Michelle	done	1			1	Generation	0	0	0	1	0	1	1	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	4	1	0	2	4	0	0	0	0	0	2	1	0	6	2	2	0	5	0	1	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
2018	ICML		Self-Attention Generative Adversarial Networks	http://proceedings.mlr.press/v97/zhang19d/zhang19d.pdf	Ria																																																																																	
																																																																																						
2018	ICML		Efficient Neural Architecture Search via Parameter Sharing	http://export.arxiv.org/pdf/1802.03268	Ria	done	1			1	not sure	0	5	0	1	2	0	0	0	0	0	1	0	0	0	0	4	6	1	0	0	0	0	0	0	6	1	0	2	6	0	0	0	0	0	0	1	0	4	0	1	0	0	1	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	4
2018	ICML		Efficient Neural Architecture Search via Parameter Sharing	http://export.arxiv.org/pdf/1802.03268	Michelle																																																																																	
																																																																																						
2018	ICML		Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor	http://export.arxiv.org/pdf/1801.01290	Ria		1																																																																															
2018	ICML		Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor	http://export.arxiv.org/pdf/1801.01290	Abeba	done				2	Reinforcement Learning	0	4	1	1	1	2	0	5	1	5	3	0	1	0	0	2	1	2	0	0	0	0	0	1	6	0	0	2	7	0	0	0	0	0	1	1	2	4	2	4	0	0	4	0	2	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2018	ICML		IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures	https://export.arxiv.org/pdf/1802.01561	Dallas	done	1			1	Reinforcement Learning	0	7	2	4	1	4	0	0	0	0	6	0	0	0	0	0	2	0	0	0	0	0	0	0	5	0	1	0	1	2	0	5	0	0	2	0	0	0	1	0	0	0	0	1	1	0	0	0	5	1	8	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures	https://export.arxiv.org/pdf/1802.01561	Ravit																																																																																	
																																																																																						
2018	ICML		Addressing Function Approximation Error in Actor-Critic Methods	https://arxiv.org/abs/1802.09477	Dallas	done	1			1	Reinforcement Learning	0	5	0	3	1	0	0	0	0	1	2	0	1	0	0	0	0	0	0	0	0	2	0	0	7	18	0	5	0	1	0	0	0	0	0	0	2	2	2	3	0	1	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		Addressing Function Approximation Error in Actor-Critic Methods	https://arxiv.org/abs/1802.09477	Michelle																																																																																	
																																																																																						
2018	ICML		Disentangling by Factorising	http://proceedings.mlr.press/v80/kim18b.html	Dallas	done	1			0	Representation Learning	0	7	1	0	0	0	0	1	0	0	3	1	3	0	1	0	0	0	0	0	0	0	0	0	0	6	0	0	0	0	0	0	1	0	1	0	0	0	0	8	0	2	1	0	2	0	0	0	0	0	0	0	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		Disentangling by Factorising	http://proceedings.mlr.press/v80/kim18b.html	Michelle																																																																																	
																																																																																						
2018	ICML		Which Training Methods for GANs do actually Converge?	http://www.nowozin.net/sebastian/papers/mescheder2018gan-convergence.pdf	Dallas	done	2			1	Generation	0	2	2	1	0	1	2	8	13	0	1	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	4	0	4	0	5	0	0	2	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		Which Training Methods for GANs do actually Converge?	http://www.nowozin.net/sebastian/papers/mescheder2018gan-convergence.pdf	Abeba	done				1	generation	0	2	10	0	0	0	0	0	3	0	1	2	2	0	0	0	0	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	8	0	0	0	2	0	0	3	0	0	0	0	1	0	1	0	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0
																																																																																						
2018	ICML		A Convergence Theory for Deep Learning via Over-Parameterization	https://arxiv.org/pdf/1811.03962v3.pdf	Michelle	done	1		"not sure if I should have annotated 1.1 and 1.2, technically part of Introduction but those sections are often not part of the Introduction in other papers. I included it in my count"	1	Understanding / Theoretical	0	0	4	10	6	0	0	8	11	0	2	0	0	0	0	0	0	0	0	0	0	0	1	0	2	5	3	0	8	4	0	0	0	0	0	2	2	14	1	2	3	8	0	0	6	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		A Convergence Theory for Deep Learning via Over-Parameterization	https://arxiv.org/pdf/1811.03962v3.pdf	Ravit																																																																																	
																																																																																						
2018	ICML		Gradient Descent Finds Global Minima of Deep Neural Networks	https://icml.cc/media/Slides/icml/2019/grandball(11-14-00)-11-15-15-4366-gradient_descen.pdf	Willie	done	1			1	Understanding / Theoretical	0	1	0	3	3	0	0	10	10	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	0	0	0	2	0	0	0	0	0	0	0	0	10	0	3	0	1	0	0	6	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		Gradient Descent Finds Global Minima of Deep Neural Networks	https://icml.cc/media/Slides/icml/2019/grandball(11-14-00)-11-15-15-4366-gradient_descen.pdf	Ria																																																																																	
																																																																																						
2018	ICML		Stronger generalization bounds for deep nets via a compression approach	http://proceedings.mlr.press/v80/arora18b/arora18b.pdf	Willie	done	1			3	Understanding / Theoretical	0	0	1	16	3	3	0	12	11	0	11	1	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	11	0	9	1	1	4	0	0	1	21	0	0	0	2	0	0	0	0	0	0	0	0	0	7	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2018	ICML		Stronger generalization bounds for deep nets via a compression approach	http://proceedings.mlr.press/v80/arora18b/arora18b.pdf	Dallas																																																																																	
																																																																																						
2018	ICML		Black-box Adversarial Attacks with Limited Queries and Information	http://proceedings.mlr.press/v80/ilyas18a/ilyas18a.pdf	Willie	done	2			2	Defenses	0	6	0	2	0	6	0	1	0	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	1	0	0	14	0	0	0	0	0	0	0	0	0	5	0	0	1	32	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	28	0	0	0
2018	ICML		Black-box Adversarial Attacks with Limited Queries and Information	http://proceedings.mlr.press/v80/ilyas18a/ilyas18a.pdf	Abeba	done				2	generation/classification/defenses	0	10	0	1	1	1	0	2	1	0	1	8	0	0	0	3	5	0	0	0	0	0	0	0	2	1	0	0	3	0	0	0	0	0	3	2	0	7	1	2	0	0	0	0	0	0	0	0	0	0	0	5	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	11	0	4	0
																																																																																						
2009	ICML		Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations	http://icml2009.org/papers/571.pdf	Abeba	done	1			1	generation	0	3	1	2	2	0	3	0	0	1	1	1	0	0	1	0	4	1	0	0	0	0	0	0	3	0	0	0	0	1	0	1	2	0	0	2	0	0	0	0	0	1	0	0	0	0	0	0	0	0	4	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations	http://icml2009.org/papers/571.pdf	Ravit																																																																																	
																																																																																						
2009	ICML		Online dictionary learning for sparse coding	http://icml2009.org/papers/364.pdf	Abeba	done	1			1	learning	0	3	0	1	2	0	0	0	0	3	6	1	0	0	0	0	0	1	0	0	0	0	1	0	1	0	1	2	0	1	1	6	1	2	4	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Online dictionary learning for sparse coding	http://icml2009.org/papers/364.pdf	Ria																																																																																	
																																																																																						
2009	ICML		Curriculum learning	http://icml2009.org/papers/119.pdf	Abeba	done	1			1	learning	0	2	4	6	0	0	0	1	0	0	7	0	2	0	6	0	0	0	2	0	0	0	0	2	1	0	0	0	1	0	0	0	0	0	1	3	3	1	0	1	0	1	5	0	0	0	0	0	0	0	0	0	10	0	2	0	0	0	0	0	0	0	1	0	4	0	0	0	0	0	0	0	0	0	0
2009	ICML		Curriculum learning	http://icml2009.org/papers/119.pdf	Dallas																																																																																	
																																																																																						
2010	ICML		Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design	https://icml.cc/Conferences/2010/papers/422.pdf	Abeba		1			1	optimization	0	7	2	1	3	0	0	3	2	1	7	3	5	0	0	2	0	0	0	0	0	0	0	0	3	0	0	0	1	0	0	0	0	0	0	1	6	0	3	0	0	1	1	0	0	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
2010	ICML		Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design	https://icml.cc/Conferences/2010/papers/422.pdf	Willie																																																																																	
																																																																																						
2009	ICML		Group lasso with overlap and graph lasso	http://icml2009.org/papers/471.pdf	Ravit	done	1			3	not sure	0	2	0	2	0	0	0	3	0	0	0	0	1	0	0	0	0	1	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	2	0	0	0	0	0	0	1	0	0	0	0	0	1	5	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Group lasso with overlap and graph lasso	http://icml2009.org/papers/471.pdf	Ria																																																																																	
																																																																																						
2009	ICML		Learning structural SVMs with latent variables	http://icml2009.org/papers/420.pdf	Ravit	done	1			2	Prediction	0	0	0	1	5	0	0	3	0	0	0	1	0	0	0	0	0	0	5	0	0	0	0	0	1	0	0	0	2	0	0	0	0	0	0	0	2	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Learning structural SVMs with latent variables	http://icml2009.org/papers/420.pdf	Michelle																																																																																	
																																																																																						
2009	ICML		Feature hashing for large scale multitask learning	http://icml2009.org/papers/407.pdf	Ravit	done	1			2	Classification	0	2	0	0	2	0	0	0	0	0	2	0	3	0	0	0	8	0	0	0	0	0	0	0	2	0	0	0	0	0	3	0	0	0	1	0	0	1	0	0	0	2	0	0	0	0	0	0	0	0	0	3	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Feature hashing for large scale multitask learning	http://icml2009.org/papers/407.pdf	Willie																																																																																	
																																																																																						
2009	ICML		Evaluation methods for topic models	http://dirichlet.net/pdf/wallach09evaluation.pdf	Michelle	done	2			1	Evaluation	0	1	3	1	3	0	0	0	0	2	3	0	0	0	0	0	1	0	0	0	1	0	0	0	2	6	0	0	2	0	0	0	0	0	0	0	0	4	0	0	0	2	0	0	1	0	0	0	0	0	0	3	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Evaluation methods for topic models	http://dirichlet.net/pdf/wallach09evaluation.pdf	Abeba	done				1	evaluating (?) not sure 	0	1	1	1	3	0	0	0	0	0	2	0	2	0	0	0	0	0	1	0	1	0	0	0	2	7	0	0	2	0	0	0	0	0	0	0	1	2	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
																																																																																						
2009	ICML		Multi-view clustering via canonical correlation analysis	http://icml2009.org/papers/317.pdf	Ria	done (abeba)	1			2	classification	0	2	4	1	1	2	0	1	1	1	6	1	0	0	0	0	1	0	3	0	0	0	0	0	5	0	0	0	6	0	0	0	0	0	0	2	1	9	0	0	0	1	3	0	0	0	0	0	1	0	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	1	0	0
2009	ICML		Multi-view clustering via canonical correlation analysis	http://icml2009.org/papers/317.pdf	Ravit																																																																																	
																																																																																						
2009	ICML		An accelerated gradient method for trace norm minimization	http://icml2009.org/papers/151.pdf	Ria	done (abeba)	1			3	understanding/theory/not sure 	0	4	1	0	3	0	0	1	1	2	3	1	0	0	0	2	1	0	2	0	0	0	0	0	1	0	0	0	7	0	0	1	0	1	1	0	5	2	1	1	0	0	2	0	4	0	0	2	0	0	0	1	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2
2009	ICML		An accelerated gradient method for trace norm minimization	http://icml2009.org/papers/151.pdf	Dallas																																																																																	
																																																																																						
2009	ICML		Learning with structured sparsity	https://www.jmlr.org/papers/volume12/huang11b/huang11b.pdf	Michelle	done	1			1	Theory / something else??	0	1	0	0	2	0	0	8	9	4	2	1	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	3	0	0	0	0	0	1	0	0	2	1	1	0	0	0	0	6	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2009	ICML		Learning with structured sparsity	https://www.jmlr.org/papers/volume12/huang11b/huang11b.pdf	Willie																																																																																	
																																																																																						
2009	ICML		Large-scale deep unsupervised learning using graphics processors	http://icml2009.org/papers/218.pdf	Ria		1																																																																															
2009	ICML		Large-scale deep unsupervised learning using graphics processors	http://icml2009.org/papers/218.pdf	Abeba	done				2	unsupervised learning??	0	1	3	0	0	0	0	0	0	0	0	2	0	0	0	1	12	2	3	0	0	0	0	0	3	0	0	0	2	1	1	2	1	0	0	5	3	2	1	1	0	0	0	0	2	0	2	2	12	1	3	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5
																																																																																						
2008	ICML		A unified architecture for natural language processing:deep neural networks with multitask learning	http://icml2008.cs.helsinki.fi/papers/391.pdf	Dallas	done	1		GOOD example	2	classification	0	2	0	6	0	0	0	0	0	0	1	0	0	0	0	0	2	0	3	0	0	0	0	0	2	1	0	2	0	0	0	0	2	0	0	0	0	3	1	0	0	1	0	0	1	0	0	0	0	0	0	1	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1
2008	ICML		A unified architecture for natural language processing:deep neural networks with multitask learning	http://icml2008.cs.helsinki.fi/papers/391.pdf	Ravit																																																																																	
																																																																																						
2008	ICML		Extracting and composing robust features with denoising autoencoders	http://icml2008.cs.helsinki.fi/papers/592.pdf	Ria	done (abeba)	1			1	unsupervised learning	0	3	1	1	0	5	0	0	2	0	5	0	3	0	0	0	0	0	0	0	0	0	0	0	5	0	0	0	1	0	0	0	0	0	0	2	3	2	1	0	0	2	0	0	0	0	0	0	0	0	0	0	2	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		Extracting and composing robust features with denoising autoencoders	http://icml2008.cs.helsinki.fi/papers/592.pdf	Dallas																																																																																	
																																																																																						
2008	ICML		Bayesian probabilistic matrix factorization using Markov chain Monte Carlo	http://icml2008.cs.helsinki.fi/papers/600.pdf	Michelle	done	1			1	Understanding(?)	0	1	2	0	0	0	0	0	0	0	0	0	0	0	0	0	5	0	0	0	0	0	0	1	1	3	0	0	3	0	0	0	0	0	1	2	1	2	0	1	0	3	0	0	3	0	0	0	1	0	4	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2
2008	ICML		Bayesian probabilistic matrix factorization using Markov chain Monte Carlo	http://icml2008.cs.helsinki.fi/papers/600.pdf	Willie																																																																																	
																																																																																						
2008	ICML		Efficient projections onto the l1-ball for learning in high dimensions	http://icml2008.cs.helsinki.fi/papers/361.pdf	Michelle	done	2			1	Understanding / Optimization / Theory	0	0	0	2	0	0	0	0	6	1	1	0	0	0	0	0	1	0	0	0	0	0	0	0	2	0	0	2	4	1	2	2	0	0	1	0	2	7	1	0	0	0	0	0	2	0	1	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2
2008	ICML		Efficient projections onto the l1-ball for learning in high dimensions	http://icml2008.cs.helsinki.fi/papers/361.pdf	Abeba	done				1	not sure 	0	1	0	3	0	0	0	4	0	0	2	3	2	0	0	0	3	0	1	0	1	0	0	0	4	0	0	2	4	0	0	0	0	0	1	0	7	6	0	0	0	0	2	0	1	0	1	0	0	0	0	0	0	0	3	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	2
																																																																																						
2008	ICML		A dual coordinate descent method for large-scale linear SVM	http://icml2008.cs.helsinki.fi/papers/166.pdf	Willie	done	1			1	Classification/Prediction	0	1	4	0	1	0	0	2	2	0	4	0	0	0	0	0	8	0	0	0	0	0	0	0	1	0	0	2	11	0	0	0	0	0	0	0	3	18	0	0	0	0	0	0	0	0	3	0	0	0	3	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		A dual coordinate descent method for large-scale linear SVM	http://icml2008.cs.helsinki.fi/papers/166.pdf	Ravit																																																																																	
																																																																																						
2008	ICML		Training restricted Boltzmann machines using approximations to the likelihood gradient	http://icml2008.cs.helsinki.fi/papers/638.pdf	Willie	done	1			1	Classification/Prediction	0	3	2	1	0	0	0	1	1	4	3	0	0	0	0	0	0	0	0	0	0	0	0	0	9	1	0	1	6	0	0	0	1	0	0	0	0	3	0	0	0	1	0	0	1	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		Training restricted Boltzmann machines using approximations to the likelihood gradient	http://icml2008.cs.helsinki.fi/papers/638.pdf	Ria																																																																																	
																																																																																						
2008	ICML		Classification using discriminative restricted Boltzmann machines	http://icml2008.cs.helsinki.fi/papers/601.pdf	Willie	done	1			1	Classification	0	2	3	2	12	0	0	0	1	1	1	0	0	0	0	0	0	0	0	0	0	0	0	0	1	0	0	0	1	0	0	0	0	0	0	1	0	4	0	0	0	0	0	0	0	0	0	0	0	0	2	2	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		Classification using discriminative restricted Boltzmann machines	http://icml2008.cs.helsinki.fi/papers/601.pdf	Michelle																																																																																	
																																																																																						
2008	ICML		Grassmann discriminant analysis: a unifying view on subspace-based learning	http://icml2008.cs.helsinki.fi/papers/312.pdf	Willie	done	1			1	Classification/Understanding	0	2	2	0	1	2	0	3	3	1	2	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	2	1	0	0	0	0	0	0	0	1	5	4	0	0	1	0	0	0	0	0	0	0	0	0	5	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		Grassmann discriminant analysis: a unifying view on subspace-based learning	http://icml2008.cs.helsinki.fi/papers/312.pdf	Michelle																																																																																	
																																																																																						
2008	ICML		Listwise approach to learning to rank: theory and algorithm	http://icml2008.cs.helsinki.fi/papers/167.pdf	Michelle	done	1			1	Understanding / Theoretical	0	5	0	0	1	0	0	12	2	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	3	2	0	0	3	0	0	0	0	0	3	1	0	4	0	1	0	2	0	0	2	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		Listwise approach to learning to rank: theory and algorithm	http://icml2008.cs.helsinki.fi/papers/167.pdf	Ravit																																																																																	
																																																																																						
2008	ICML		Learning diverse rankings with multi-armed bandits	http://icml2008.cs.helsinki.fi/papers/264.pdf	Abeba	done	1		written in unusually short pros 	1	Learning/Optimization	0	3	0	0	1	0	1	2	1	1	1	0	0	0	0	1	1	0	0	0	0	1	0	0	4	0	0	0	0	0	0	4	3	0	0	0	2	2	0	1	0	0	2	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	4	0	0	0	0	0	0	0	0	0	0	0	0	0	1
2008	ICML		Learning diverse rankings with multi-armed bandits	http://icml2008.cs.helsinki.fi/papers/264.pdf	Michelle																																																																																	
																																																																																						
2008	ICML		Confidence-weighted linear classification	http://icml2008.cs.helsinki.fi/papers/322.pdf	Abeba	done	1			1	Classification	0	4	1	0	0	0	0	1	0	2	2	0	0	0	0	0	1	0	0	0	1	0	0	0	2	1	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	5	0	1	0	0	0	5	0	0	0	0	1	0	0	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	0	4
2008	ICML		Confidence-weighted linear classification	http://icml2008.cs.helsinki.fi/papers/322.pdf	Dallas																																																																																	
																																																																																						
2008	ICML		On the quantitative analysis of deep belief networks	http://icml2008.cs.helsinki.fi/papers/573.pdf	Ravit	done	1			1	Generation	0	2	0	4	4	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	5	4	0	0	6	0	0	0	0	0	0	3	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	2	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
2008	ICML		On the quantitative analysis of deep belief networks	http://icml2008.cs.helsinki.fi/papers/573.pdf	Michelle																																																																																	
																																																																																						
STATS	# with 1 anns	101																																																																																				
	# with 2 anns	39																																																																																				
		0.385416667																																																																																				
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															
																																																																																						
																																																																																						
							0																																																																															